# Behavioral manipulations of deep and shallow thinking in a single forward pass

This repository contains code and data for the BehavioralML @ NeurIPS Workshop paper.

The materials are organized into the following main folders:
- `analysis`: contains Jupyter notebooks for analyzing the model outputs and generating figures
- `data`: contains stimuli (`data/stimuli`) and prompt contrasts (`data/prompt_contrasts.csv`)
- `model_output`: contains model outputs from experiments
- `behavioral`: contains code for implementing the behavioral experiments
- `logit_lens`: contains code for implementing the logit lens experiments

**Please note:** throughout the code and data, you will see labels such as "fast" and "slow".
These conceptually correspond to the terms "shallow" and "deep" used in the paper.

## Stimuli: Cognitive Reflection Task

The stimuli for the CRT dataset (Hagendorff et al. 2023) are found in the files
`crt*.csv` in the folder `data/stimuli`. 
These files were generated by running `python make_crt_stimuli.py`.

Please note a few small differences from the original source material:
- Fixed a few typos (e.g., "1 minutes" --> "1 minute")
- Standardized all answers given in dollar values to $X.XX format

## Running behavioral experiments

To evaluate a given model on a given task, run:
```bash
bash run_behavioral_experiment.sh <MODEL_ID> <TASK>
```
`<MODEL_ID>` should be a Huggingface model identifier, 
and `<TASK>` must be one of `crt1`, `crt2`, or `crt3`.
Before running the script, please point the `CACHE_DIR` variable in the script to the path
where you would like to save the downloaded model checkpoints.

By default, the script will use user prompts and save output CSV files to the folder
`model_output/no-system-prompt`. Each result file is named `<TASK>_<MODEL_ID>.csv`.
If you would like to change the arguments to the experiment,
please see the `run_behavioral_experiment.py` script in the `behavioral` folder.

If you evaluate gated Huggingface models, you will need to specify your
Huggingface token. By default, the code looks for a file called `hf_token.txt`
which contains your token (this file is ignored by git).

Our behavioral analysis uses the `minicons` library. Please see their
[documentation](https://github.com/kanishkamisra/minicons) for more details.

## Running logit lens experiments

To run the logit lens analysis on a given model and task, run:
```bash
bash run_logit_lens.sh <MODEL_ID> <TASK>
```
As with the behavioral experiments,
`<MODEL_ID>` should be a Huggingface model identifier, 
and `<TASK>` must be one of `crt1`, `crt2`, or `crt3`.
Before running the script, please point the `CACHE_DIR` variable in the script to the path
where you would like to save the downloaded model checkpoints.

In our paper, we only report results from Llama-2 7B (`meta-llama/Llama-2-7b-chat-hf`).

Our logit lens analysis uses the `nnsight` library. Please see their
[documentation](https://nnsight.net/) for more details.

## Reproducing figures

To reproduce the figures from the paper, run the notebooks in the `analysis`
folder:
- `behavioral.ipynb` will reproduce Figure 1 (the behavioral
results)
- `logit_lens.ipynb` will reproduce Figures 2a and 2b
(the logit lens results)